{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_utils import load_model, generate\n",
    "import os\n",
    "\n",
    "target_lang = \"fr\"\n",
    "path = os.path.join(\"OUTPUT-CM\", f\"en-{target_lang}\")\n",
    "model, tokenizer = load_model(path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config. model overview: {'no': 'Helsinki-NLP/opus-mt-en-gmq', 'lt': 'Helsinki-NLP/opus-mt-en-bat', 'pl': 'Helsinki-NLP/opus-mt-en-zlw', 'hu': 'Helsinki-NLP/opus-mt-en-urj', 'fr': 'Helsinki-NLP/opus-mt-en-roa', 'ms': 'Helsinki-NLP/opus-mt-en-map', 'sq': 'Helsinki-NLP/opus-mt-en-sq', 'eu': 'Helsinki-NLP/opus-mt-en-eu'}\n",
      "Comp.rate=0.5\n",
      "MM results\n",
      "[\"- D'accord, Mr. Conroy, me diga su ubicacion?\", 'No lo sé, en un cadaleu, en un cadaleu, non lo sé. Ajude-me, por favor, tengo miedo.']\n",
      "CM results\n",
      "['M. Conroy, dites-moi où.', \"Je suis dans un cercueil, j'ai peur.\"]\n",
      "\n",
      "Comp.rate=0.7\n",
      "MM results\n",
      "['- Ok, Mr. Conroy, me diga su ubicacion?', 'No lo sé, en un cadaleu, en un cadaleu, non lo sé. Ajude-me, por favor, tengo miedo.']\n",
      "CM results\n",
      "['M. Conroy, dites-moi où vous êtes.', 'Je suis dans un cercueil, je ne sais pas où.']\n",
      "\n",
      "Comp.rate=1.0\n",
      "MM results\n",
      "['- Ok, Mr. Conroy, me diga su ubicacion?', '- Non lo sé, en un cadaleu, en un cadaleu, non sé adónde. Por favor, ajude-me, estou asustada.']\n",
      "CM results\n",
      "['M. Conroy, pouvez-vous me dire où vous êtes ?', 'Je suis dans un cercueil, je ne sais pas où.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from config import get_compression_prefix, COMPRESSION_RATIOS\n",
    "\n",
    "sents = [\n",
    "    \"- Okay, Mr. Conroy, can you tell me your location?\",\n",
    "    \"- I don't know. I'm in a coffin, I don't know where. Please help me, I'm scared.\"\n",
    "]\n",
    "\n",
    "for c in [0.5, 0.7, 1.0]:\n",
    "    print(f\"Comp.rate={c}\")\n",
    "    model1_path = os.path.join(\"OUTPUT-MM\", f\"en-{target_lang}\", str(c))\n",
    "    model1, tokenizer1 = load_model(path=model1_path)\n",
    "    print(\"MM results\")\n",
    "    print(generate(model1, tokenizer1, source_texts=sents))\n",
    "\n",
    "    print(\"CM results\")\n",
    "    prefix = get_compression_prefix(c, target_lang)\n",
    "    print(generate(model, tokenizer, source_texts=sents, prefix=prefix))\n",
    "\n",
    "    \n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
